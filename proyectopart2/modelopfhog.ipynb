{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle"
      ],
      "metadata": {
        "id": "eZ8TtlVtPlTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar los descriptores HOG desde el CSV\n",
        "data = pd.read_csv('/content/drive/MyDrive/hog_train.csv', header=None)\n",
        "\n",
        "# Separar características (X) y etiquetas (y)\n",
        "X = data.iloc[:, 1:].values\n",
        "y = data.iloc[:, 0].values\n",
        "\n",
        "# Dividir los datos en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear y entrenar el modelo MLP\n",
        "clf = MLPClassifier(solver='adam',\n",
        "                    activation='relu',\n",
        "                    alpha=.001,\n",
        "                    hidden_layer_sizes=(512, 128, 10),\n",
        "                    random_state=1,\n",
        "                    max_iter=500)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluar el modelo\n",
        "train_pred = clf.predict(X_train)\n",
        "train_accuracy = np.mean(train_pred == y_train)\n",
        "\n",
        "test_pred = clf.predict(X_test)\n",
        "test_accuracy = np.mean(test_pred == y_test)\n",
        "\n",
        "print(\"Training accuracy: {}\".format(train_accuracy))\n",
        "print(\"Testing accuracy: {}\".format(test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Svaab08P58s",
        "outputId": "ae0207df-3978-45a5-884d-b0798577b550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.9996875\n",
            "Testing accuracy: 0.9793333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import skl2onnx\n",
        "from skl2onnx import convert_sklearn\n",
        "from skl2onnx.common.data_types import FloatTensorType\n",
        "\n",
        "# Cargar el modelo guardado de scikit-learn\n",
        "model_filename = '/content/drive/MyDrive/mlp_model.pkl'\n",
        "with open(model_filename, 'rb') as file:\n",
        "    sklearn_model = pickle.load(file)\n",
        "\n",
        "# Supongamos que las características tienen una forma de (n_samples, n_features)\n",
        "n_features = sklearn_model.coefs_[0].shape[0]\n",
        "\n",
        "# Convertir el modelo de scikit-learn a ONNX\n",
        "initial_type = [('float_input', FloatTensorType([None, n_features]))]\n",
        "onnx_model = convert_sklearn(sklearn_model, initial_types=initial_type)\n",
        "\n",
        "# Guardar el modelo ONNX en un archivo\n",
        "onnx_model_filename = '/content/drive/MyDrive/mlp_model.onnx'\n",
        "with open(onnx_model_filename, 'wb') as file:\n",
        "    file.write(onnx_model.SerializeToString())\n",
        "\n",
        "print(\"Modelo ONNX guardado en: {}\".format(onnx_model_filename))\n"
      ],
      "metadata": {
        "id": "_vp3L6nUuji7",
        "outputId": "bdc28bb4-6297-46fd-c8fb-d7232c742846",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo ONNX guardado en: /content/drive/MyDrive/mlp_model.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf2onnx\n"
      ],
      "metadata": {
        "id": "0BgX1nKcQRlk",
        "outputId": "7af43aa6-2666-4edd-c699-a3e5b40a0a7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf2onnx in /usr/local/lib/python3.10/dist-packages (1.16.1)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.25.2)\n",
            "Requirement already satisfied: onnx>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.16.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (24.3.25)\n",
            "Collecting protobuf~=3.20 (from tf2onnx)\n",
            "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2024.7.4)\n",
            "Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.4\n",
            "    Uninstalling protobuf-4.25.4:\n",
            "      Successfully uninstalled protobuf-4.25.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "onnxconverter-common 1.14.0 requires protobuf==3.20.2, but you have protobuf 3.20.3 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.17.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "b3572b2e84e7424db20e72a4f924d94e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m tf2onnx.convert --opset 13 --onnx /content/drive/MyDrive/mlp_model.onnx --output /content/drive/MyDrive/mlp_model_tf.pb\n"
      ],
      "metadata": {
        "id": "OBKs4wdDQvFC",
        "outputId": "dde55c4b-c6b4-4599-c6e0-c53046d67fc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "usage: convert.py [-h] [--input INPUT] [--graphdef GRAPHDEF] [--saved-model SAVED_MODEL]\n",
            "                  [--tag TAG] [--signature_def SIGNATURE_DEF]\n",
            "                  [--concrete_function CONCRETE_FUNCTION] [--checkpoint CHECKPOINT]\n",
            "                  [--keras KERAS] [--tflite TFLITE] [--tfjs TFJS] [--large_model]\n",
            "                  [--output OUTPUT] [--inputs INPUTS] [--outputs OUTPUTS]\n",
            "                  [--ignore_default IGNORE_DEFAULT] [--use_default USE_DEFAULT]\n",
            "                  [--rename-inputs RENAME_INPUTS] [--rename-outputs RENAME_OUTPUTS]\n",
            "                  [--use-graph-names] [--opset OPSET] [--dequantize] [--custom-ops CUSTOM_OPS]\n",
            "                  [--extra_opset EXTRA_OPSET] [--load_op_libraries LOAD_OP_LIBRARIES]\n",
            "                  [--target {rs4,rs5,rs6,caffe2,tensorrt,nhwc}] [--continue_on_error] [--verbose]\n",
            "                  [--debug] [--output_frozen_graph OUTPUT_FROZEN_GRAPH]\n",
            "                  [--inputs-as-nchw INPUTS_AS_NCHW] [--outputs-as-nchw OUTPUTS_AS_NCHW]\n",
            "convert.py: error: unrecognized arguments: --onnx /content/drive/MyDrive/mlp_model.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Cargar el modelo TensorFlow guardado\n",
        "saved_model_dir = \"/content/drive/MyDrive/mlp_model_tf\"\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Guardar el modelo TensorFlow Lite en un archivo\n",
        "tflite_model_filename = '/content/drive/MyDrive/mlp_model.tflite'\n",
        "with open(tflite_model_filename, 'wb') as file:\n",
        "    file.write(tflite_model)\n",
        "\n",
        "print(\"Modelo TensorFlow Lite guardado en: {}\".format(tflite_model_filename))\n"
      ],
      "metadata": {
        "id": "ZAxfvc8tQ6Fv",
        "outputId": "faa6cc5c-8417-4efb-9e73-1d516986389d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo TensorFlow Lite guardado en: /content/drive/MyDrive/mlp_model.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IXB_Oa49Q_UQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}